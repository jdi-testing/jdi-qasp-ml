{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "from time import sleep\n",
    "\n",
    "prefix = os.getcwd().split(\"jdi-qasp-ml\")[0]\n",
    "sys.path.append(os.path.join(prefix, \"jdi-qasp-ml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(prefix, \"jdi-qasp-ml\", \"data/mui_dataset\")\n",
    "\n",
    "SITE_DFS = [\n",
    "    p\n",
    "    for p in glob(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/mui_dataset/df/site*')\n",
    "]\n",
    "DF_NAMES = [re.search(\"site-[0-9]+\", nm)[0] for nm in SITE_DFS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df = pd.DataFrame()\n",
    "# for i, df_path in tqdm(enumerate(SITE_DFS)):\n",
    "#     df = pd.read_pickle(df_path)\n",
    "#     df['site'] = DF_NAMES[i]\n",
    "\n",
    "#     par_childs = {par:list(df[df.parent_id==par].element_id.unique()) for par in df.parent_id.unique()}\n",
    "\n",
    "#     def find_all_childs(elem_id):\n",
    "#         if par_childs.get(elem_id) is None:\n",
    "#             return []\n",
    "#         else:\n",
    "#             res = []\n",
    "#             for i in par_childs.get(elem_id):\n",
    "#                 res.append(i)\n",
    "#                 res.extend(find_all_childs(i))\n",
    "#             return res\n",
    "    \n",
    "#     df['all_followers'] = df['element_id'].apply(find_all_childs)\n",
    "\n",
    "#     df['STRING'] = df.attributes.apply((lambda x: '' if x is None else x.get('class', \"\") + \" \" + x.get('type', \"\") + \" \" + x.get('role', \"\")))\n",
    "#     df['STRING'] = df.tag_name.str.lower().str.cat(df['STRING'], sep=\" \")\n",
    "#     df['LABEL'] = df.attributes.apply(lambda x: None if x is None else x.get('data-label'))\n",
    "#     df = df[[\"site\", \"element_id\", \"parent_id\", \"all_followers\", \"STRING\", \"LABEL\"]]\n",
    "#     df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     elem_string_dict = {k:v.get('STRING') for k,v in df[['STRING']].set_index(df.element_id).fillna('').T.to_dict().items()}\n",
    "\n",
    "#     def concat_all_strings(list):\n",
    "#         res = ''\n",
    "#         for l in list:\n",
    "#             res = res + elem_string_dict.get(l) + ' '\n",
    "#         return res\n",
    "    \n",
    "#     df['all_followers_string'] = df['all_followers'].apply(concat_all_strings)\n",
    "#     df['final_string'] = (df.STRING + ' ' + df.all_followers_string).fillna('')\n",
    "\n",
    "#     df = df[[\"site\", \"element_id\", \"parent_id\", \"final_string\", \"LABEL\"]]\n",
    "#     total_df = pd.concat([total_df, df])\n",
    "# total_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df.to_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/total_df_for_nlp_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df = pd.read_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/total_df_for_nlp_model.csv')\n",
    "# total_df.LABEL = total_df.LABEL.fillna(\"n/a\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_string(string):\n",
    "    string = re.sub(r\"(?<=\\w)([A-Z])\", r\" \\1\", string)\n",
    "    string = str(string).lower().strip()\n",
    "    return(re.sub(' +', ' ', re.sub('(-)|([0-9]+)', ' ', string).strip()))\n",
    "\n",
    "\n",
    "# total_df['final_string'] = total_df['final_string'].apply(prepare_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df.to_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/total_df_for_nlp_model_prepared.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/total_df_for_nlp_model_prepared.csv')\n",
    "total_df.LABEL = total_df.LABEL.fillna(\"n/a\")\n",
    "total_df.LABEL.replace(\"n/a\", \"unkn\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>element_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>final_string</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739896</th>\n",
       "      <td>site-13</td>\n",
       "      <td>9627524316559287764950874349</td>\n",
       "      <td>8293726446559287768833831671</td>\n",
       "      <td>div</td>\n",
       "      <td>unkn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739897</th>\n",
       "      <td>site-13</td>\n",
       "      <td>9638773789559287760038756767</td>\n",
       "      <td>8293726446559287768833831671</td>\n",
       "      <td>div</td>\n",
       "      <td>unkn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739898</th>\n",
       "      <td>site-13</td>\n",
       "      <td>4889127663559287761125737880</td>\n",
       "      <td>8293726446559287768833831671</td>\n",
       "      <td>div mui paper root mui popover paper mui paper...</td>\n",
       "      <td>unkn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739899</th>\n",
       "      <td>site-13</td>\n",
       "      <td>8651010676559287765452773916</td>\n",
       "      <td>4889127663559287761125737880</td>\n",
       "      <td>p mui typography root jss mui typography body</td>\n",
       "      <td>typography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739900</th>\n",
       "      <td>site-13</td>\n",
       "      <td>9980562521559287761155767932</td>\n",
       "      <td>8293726446559287768833831671</td>\n",
       "      <td>div</td>\n",
       "      <td>unkn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           site                    element_id                     parent_id  \\\n",
       "739896  site-13  9627524316559287764950874349  8293726446559287768833831671   \n",
       "739897  site-13  9638773789559287760038756767  8293726446559287768833831671   \n",
       "739898  site-13  4889127663559287761125737880  8293726446559287768833831671   \n",
       "739899  site-13  8651010676559287765452773916  4889127663559287761125737880   \n",
       "739900  site-13  9980562521559287761155767932  8293726446559287768833831671   \n",
       "\n",
       "                                             final_string       LABEL  \n",
       "739896                                                div        unkn  \n",
       "739897                                                div        unkn  \n",
       "739898  div mui paper root mui popover paper mui paper...        unkn  \n",
       "739899      p mui typography root jss mui typography body  typography  \n",
       "739900                                                div        unkn  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = DF_NAMES[:50]\n",
    "val_dfs = DF_NAMES[400:450]\n",
    "test_dfs = DF_NAMES[450:]\n",
    "\n",
    "train_df = total_df[total_df.site.isin(train_dfs)].copy()[['element_id', 'final_string', 'LABEL']].copy().reset_index(drop=True)\n",
    "val_df = total_df[total_df.site.isin(val_dfs)].copy()[['element_id', 'final_string', 'LABEL']].copy().reset_index(drop=True)\n",
    "test_df = total_df[total_df.site.isin(test_dfs)].copy()[['element_id', 'final_string', 'LABEL']].copy().reset_index(drop=True)\n",
    "\n",
    "# train.to_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/'+ 'nlp_train.csv', index=False)\n",
    "# val_df.to_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/'+ 'nlp_val.csv', index=False)\n",
    "# test_df.to_csv(f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/'+ 'nlp_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element_id</th>\n",
       "      <th>final_string</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6533486216559833460616205753</td>\n",
       "      <td>span mui slider root mui slider color primary ...</td>\n",
       "      <td>slider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7159805062559833463754904441</td>\n",
       "      <td>div mui avatar root mui avatar square mui avat...</td>\n",
       "      <td>avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>9909531984559833468390915811</td>\n",
       "      <td>div mui avatar root mui avatar square mui avat...</td>\n",
       "      <td>avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>8242725098559833466945321206</td>\n",
       "      <td>svg mui svg icon root path</td>\n",
       "      <td>icon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3265653768559833466368332963</td>\n",
       "      <td>div mui avatar root mui avatar square mui avat...</td>\n",
       "      <td>avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73190</th>\n",
       "      <td>7140654154569241153037853244</td>\n",
       "      <td>ul mui list root mui menu list mui list paddin...</td>\n",
       "      <td>menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73198</th>\n",
       "      <td>9907290597569241159943579524</td>\n",
       "      <td>div tooltip div mui paper root mui paper eleva...</td>\n",
       "      <td>popper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73199</th>\n",
       "      <td>6530051995569241159732622655</td>\n",
       "      <td>div mui paper root mui paper elevation mui pap...</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73200</th>\n",
       "      <td>1575209453569241157856032962</td>\n",
       "      <td>p mui typography root jss mui typography body</td>\n",
       "      <td>typography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73201</th>\n",
       "      <td>3614215542569241155968521895</td>\n",
       "      <td>div mui popover root jss presentation div div ...</td>\n",
       "      <td>popover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10663 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         element_id  \\\n",
       "112    6533486216559833460616205753   \n",
       "126    7159805062559833463754904441   \n",
       "127    9909531984559833468390915811   \n",
       "128    8242725098559833466945321206   \n",
       "130    3265653768559833466368332963   \n",
       "...                             ...   \n",
       "73190  7140654154569241153037853244   \n",
       "73198  9907290597569241159943579524   \n",
       "73199  6530051995569241159732622655   \n",
       "73200  1575209453569241157856032962   \n",
       "73201  3614215542569241155968521895   \n",
       "\n",
       "                                            final_string       LABEL  \n",
       "112    span mui slider root mui slider color primary ...      slider  \n",
       "126    div mui avatar root mui avatar square mui avat...      avatar  \n",
       "127    div mui avatar root mui avatar square mui avat...      avatar  \n",
       "128                           svg mui svg icon root path        icon  \n",
       "130    div mui avatar root mui avatar square mui avat...      avatar  \n",
       "...                                                  ...         ...  \n",
       "73190  ul mui list root mui menu list mui list paddin...        menu  \n",
       "73198  div tooltip div mui paper root mui paper eleva...      popper  \n",
       "73199  div mui paper root mui paper elevation mui pap...       paper  \n",
       "73200      p mui typography root jss mui typography body  typography  \n",
       "73201  div mui popover root jss presentation div div ...     popover  \n",
       "\n",
       "[10663 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[~(train_df.LABEL == \"unkn\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>element_id</th>\n",
       "      <th>final_string</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6533486216559833460616205753</td>\n",
       "      <td>span mui slider root mui slider color primary ...</td>\n",
       "      <td>slider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       element_id  \\\n",
       "112  6533486216559833460616205753   \n",
       "\n",
       "                                          final_string   LABEL  \n",
       "112  span mui slider root mui slider color primary ...  slider  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.element_id==\"6533486216559833460616205753\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create text pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(prepare_string(text))\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_df.final_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab['accordion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_path = os.path.join(prefix, \"jdi-qasp-ml\", \"data/mui_dataset/classes.txt\")\n",
    "with open(classes_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    classes_dict = {v.strip(): i for i, v in enumerate(lines)}\n",
    "    classes_reverse_dict = {i: v.strip() for i, v in enumerate(lines)}\n",
    "\n",
    "# train_df.LABEL = train_df.LABEL.apply(lambda x: classes_dict.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_dict[\"slider\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(prepare_string(x)))\n",
    "label_pipeline = lambda x: classes_dict.get(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 38, 1, 0, 163, 38, 0, 38]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"div MuiPaper-root MuiPopover-paper MuiPaper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data batch and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(include_lengths=True, sequential=True, tokenize=tokenizer, lower=True, use_vocab=True)\n",
    "LABEL = data.Field(sequential=False, use_vocab=True)\n",
    "ID = data.RawField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, id_field, text_field, label_field, is_test=False, **kwargs):\n",
    "        fields = [('id', id_field), ('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.LABEL if not is_test else None\n",
    "            text = row.final_string\n",
    "            id = row.element_id\n",
    "            examples.append(data.Example.fromlist([id, text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, id_field, text_field, label_field, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), id_field, text_field, label_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), id_field, text_field, label_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), id_field, text_field, label_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)\n",
    "        \n",
    "train_ds, val_ds, test_ds = DataFrameDataset.splits(id_field=ID, text_field=TEXT, label_field=LABEL, train_df=train_df, val_df=val_df, test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6533486216559833460616205753\n",
      "slider\n",
      "['span', 'mui', 'slider', 'root', 'mui', 'slider', 'color', 'primary', 'span', 'mui', 'slider', 'rail', 'span', 'mui', 'slider', 'track', 'input', 'hidden', 'span', 'mui', 'slider', 'thumb', 'mui', 'slider', 'thumb', 'color', 'primary', 'jss', 'jss', 'slider', 'span', 'jss', 'mui', 'slider', 'value', 'label', 'span', 'jss', 'span', 'jss', 'span', 'mui', 'slider', 'thumb', 'mui', 'slider', 'thumb', 'color', 'primary', 'jss', 'jss', 'slider', 'span', 'jss', 'mui', 'slider', 'value', 'label', 'span', 'jss', 'span', 'jss']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[112].id)\n",
    "print(train_ds[112].label)\n",
    "print(train_ds[112].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating vocabulary dict from train data object \n",
      "The idx of 'mui' is  40\n",
      "The string value of 4 is  button\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating vocabulary dict from train data object \")\n",
    "TEXT.build_vocab(train_ds.text)\n",
    "print(\"The idx of \\'mui\\' is \", TEXT.vocab.stoi['paper'])\n",
    "print(\"The string value of 4 is \", TEXT.vocab.itos[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating vocabulary dict from train data object \n",
      "The idx of 'slider' is  34\n",
      "The string value of 4 is  typography\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating vocabulary dict from train data object \")\n",
    "LABEL.build_vocab(train_ds.label)\n",
    "print(\"The idx of \\'slider\\' is \", LABEL.vocab.stoi['slider'])\n",
    "print(\"The string value of 4 is \", LABEL.vocab.itos[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a BucketIterator on the train_object \n",
      "\n",
      "Iterating train data (batch_size=32) \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating a BucketIterator on the train_object \")\n",
    "\n",
    "train_iter  = data.BucketIterator(\n",
    "  dataset=train_ds,\n",
    "  batch_size = 1024,\n",
    "  sort_key=lambda x: len(x.text),\n",
    "  shuffle=False,\n",
    "  device=device)\n",
    "\n",
    "val_iter  = data.BucketIterator(\n",
    "  dataset=val_ds,\n",
    "  batch_size = 1024,\n",
    "  sort_key=lambda x: len(x.text),\n",
    "  shuffle=False,\n",
    "  device=device)\n",
    "\n",
    "print(\"\\nIterating train data (batch_size=32) \")\n",
    "for item in train_iter:\n",
    "  # print(\"\\n=====\\n\")\n",
    "  # print(item.id)\n",
    "  # print(item.text)\n",
    "  # print(item.label)\n",
    "  if '6533486216559833460616205753' in item.id:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[273,  96, 196,  ..., 245,   9,  11],\n",
       "        [ 96, 196,  84,  ...,   1,   1,   1],\n",
       "        [196,   1,   1,  ...,   1,   1,   1],\n",
       "        ...,\n",
       "        [  9,  11,   9,  ...,   1,   1,   1],\n",
       "        [  9,   2,  40,  ...,   1,   1,   1],\n",
       "        [  9,   2, 118,  ...,   1,   1,   1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.text[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " 'head',\n",
       " 'meta',\n",
       " 'link',\n",
       " 'meta',\n",
       " 'meta',\n",
       " 'meta',\n",
       " 'link',\n",
       " 'link',\n",
       " 'title',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'style',\n",
       " 'body',\n",
       " 'noscript',\n",
       " 'div',\n",
       " 'div',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'color',\n",
       " 'primary',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'rail',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'track',\n",
       " 'input',\n",
       " 'hidden',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'thumb',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'thumb',\n",
       " 'color',\n",
       " 'primary',\n",
       " 'jss',\n",
       " 'jss',\n",
       " 'slider',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'value',\n",
       " 'label',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'thumb',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'thumb',\n",
       " 'color',\n",
       " 'primary',\n",
       " 'jss',\n",
       " 'jss',\n",
       " 'slider',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'slider',\n",
       " 'value',\n",
       " 'label',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'jss',\n",
       " 'div',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'root',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'avatar',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'avatar',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'avatar',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'avatar',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'group',\n",
       " 'avatar',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'nav',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'color',\n",
       " 'text',\n",
       " 'secondary',\n",
       " 'ol',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'ol',\n",
       " 'li',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'li',\n",
       " 'a',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'link',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'link',\n",
       " 'underline',\n",
       " 'hover',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'color',\n",
       " 'inherit',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'li',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'separator',\n",
       " 'li',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'li',\n",
       " 'a',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'link',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'link',\n",
       " 'underline',\n",
       " 'hover',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'color',\n",
       " 'inherit',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'li',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'separator',\n",
       " 'li',\n",
       " 'mui',\n",
       " 'breadcrumbs',\n",
       " 'li',\n",
       " 'p',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'color',\n",
       " 'text',\n",
       " 'primary',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'disable',\n",
       " 'elevation',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'contained',\n",
       " 'group',\n",
       " 'button',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'base',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'contained',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'primary',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'contained',\n",
       " 'primary',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'disable',\n",
       " 'elevation',\n",
       " 'button',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'label',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'touch',\n",
       " 'ripple',\n",
       " 'root',\n",
       " 'button',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'base',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'contained',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'contained',\n",
       " 'primary',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'contained',\n",
       " 'primary',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'disable',\n",
       " 'elevation',\n",
       " 'button',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'button',\n",
       " 'label',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'touch',\n",
       " 'ripple',\n",
       " 'root',\n",
       " 'div',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'square',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'avatar',\n",
       " 'color',\n",
       " 'default',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'div',\n",
       " 'div',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'form',\n",
       " 'control',\n",
       " 'root',\n",
       " 'jss',\n",
       " 'label',\n",
       " 'mui',\n",
       " 'form',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'label',\n",
       " 'form',\n",
       " 'control',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'label',\n",
       " 'animated',\n",
       " 'mui',\n",
       " 'error',\n",
       " 'mui',\n",
       " 'error',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'base',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'underline',\n",
       " 'mui',\n",
       " 'error',\n",
       " 'mui',\n",
       " 'error',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'base',\n",
       " 'form',\n",
       " 'control',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'form',\n",
       " 'control',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'select',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'select',\n",
       " 'select',\n",
       " 'mui',\n",
       " 'select',\n",
       " 'select',\n",
       " 'menu',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'base',\n",
       " 'input',\n",
       " 'mui',\n",
       " 'input',\n",
       " 'input',\n",
       " 'button',\n",
       " 'span',\n",
       " 'input',\n",
       " 'mui',\n",
       " 'select',\n",
       " 'native',\n",
       " 'input',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'select',\n",
       " 'icon',\n",
       " 'path',\n",
       " 'p',\n",
       " 'mui',\n",
       " 'form',\n",
       " 'helper',\n",
       " 'text',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'error',\n",
       " 'textarea',\n",
       " 'textarea',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'paper',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'stepper',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'stepper',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'paper',\n",
       " 'elevation',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'completed',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'horizontal',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'icon',\n",
       " 'container',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'jss',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'container',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'completed',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'display',\n",
       " 'block',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'active',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'horizontal',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'horizontal',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'horizontal',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'icon',\n",
       " 'container',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'jss',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'container',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'active',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'display',\n",
       " 'block',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'disabled',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'horizontal',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'horizontal',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'disabled',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'icon',\n",
       " 'container',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'svg',\n",
       " 'icon',\n",
       " 'root',\n",
       " 'path',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'container',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'display',\n",
       " 'block',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'disabled',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'jss',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'connector',\n",
       " 'line',\n",
       " 'horizontal',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'horizontal',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'horizontal',\n",
       " 'mui',\n",
       " 'disabled',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'icon',\n",
       " 'container',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'container',\n",
       " 'span',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'step',\n",
       " 'label',\n",
       " 'label',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'body',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'display',\n",
       " 'block',\n",
       " 'div',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'backdrop',\n",
       " 'root',\n",
       " 'jss',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'circular',\n",
       " 'progress',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'circular',\n",
       " 'progress',\n",
       " 'indeterminate',\n",
       " 'progressbar',\n",
       " 'svg',\n",
       " 'mui',\n",
       " 'circular',\n",
       " 'progress',\n",
       " 'svg',\n",
       " 'circle',\n",
       " 'mui',\n",
       " 'circular',\n",
       " 'progress',\n",
       " 'circle',\n",
       " 'mui',\n",
       " 'circular',\n",
       " 'progress',\n",
       " 'circle',\n",
       " 'indeterminate',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'div',\n",
       " 'jss',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'container',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'align',\n",
       " 'items',\n",
       " 'xs',\n",
       " 'center',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'item',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'grid',\n",
       " 'xs',\n",
       " 'true',\n",
       " 'h',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'h',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'gutter',\n",
       " 'bottom',\n",
       " 'div',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'grid',\n",
       " 'item',\n",
       " 'h',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'root',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'h',\n",
       " 'mui',\n",
       " 'typography',\n",
       " 'gutter',\n",
       " 'bottom',\n",
       " 'p',\n",
       " 'mui',\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TEXT.vocab.itos[i] for i in item.text[0][:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5377782770559833469033671578'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, dimension=32):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), 64)\n",
    "        self.dimension = dimension\n",
    "        self.lstm = nn.LSTM(input_size=64,\n",
    "                            hidden_size=dimension,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc = nn.Linear(2*dimension, len(LABEL.vocab), bias=False)\n",
    "\n",
    "    def forward(self, text, text_len):\n",
    "\n",
    "        text_emb = self.embedding(text)\n",
    "\n",
    "        packed_input = pack_padded_sequence(text_emb, text_len, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        out_forward = output[range(len(output)), text_len - 1, :self.dimension]\n",
    "        out_reverse = output[:, 0, self.dimension:]\n",
    "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
    "        text_fea = self.drop(out_reduced)\n",
    "\n",
    "        text_out = self.fc(text_fea)\n",
    "\n",
    "        return text_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, optimizer, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(load_path, model, optimizer):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_folder = f'{os.path.join(prefix, \"jdi-qasp-ml\")}/data/other/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iter,\n",
    "          valid_loader = val_iter,\n",
    "          num_epochs = 5,\n",
    "          eval_every = 1000,\n",
    "          file_path = dest_folder,\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}!')\n",
    "        for batch in tqdm(train_loader):           \n",
    "            labels = batch.label.T.long().to(device)\n",
    "            print(labels)\n",
    "            text = batch.text[0].T.to(device)\n",
    "            # print(text.shape)\n",
    "            titletext_len = batch.text[1].T.to(device)\n",
    "            # print(titletext_len.shape)\n",
    "            output = model(text, titletext_len)\n",
    "            print(output)\n",
    "            optimizer.zero_grad()\n",
    "            print(\"zerograd\")\n",
    "            loss = criterion(output, labels)\n",
    "            print(\"loss\") \n",
    "            return labels, text, output           \n",
    "            loss.backward()\n",
    "            print(\"backward\")\n",
    "            optimizer.step()\n",
    "            print(\"optimizer step\")\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "                  # validation loop\n",
    "                  print(\"Validation loop\")\n",
    "                  for batch in valid_loader:\n",
    "                      labels = batch.label.T.long().to(device)\n",
    "                      text = batch.text[0].T.to(device)\n",
    "                      titletext_len = batch.text[1].T.to(device)\n",
    "                      output = model(text, titletext_len)\n",
    "\n",
    "                      loss = criterion(output, labels)\n",
    "                      valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/model.pt', model, optimizer, best_valid_loss)\n",
    "                    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "    save_metrics(file_path + '/metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Finished Training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassificationModel(len(TEXT.vocab), 128, len(LABEL.vocab)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40489"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee4251135684de6ad9b78c171d2e601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  1,  1,  ...,  1, 29,  1])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "if input is 2D, then offsets has to be None, as input is treated is a mini-batch of fixed length sequences. However, found offsets of type <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n6/xlg_j8tx7xzdv6qgxc7hwb680000gp/T/ipykernel_9081/1885079772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n6/xlg_j8tx7xzdv6qgxc7hwb680000gp/T/ipykernel_9081/3747250175.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_loader, valid_loader, num_epochs, eval_every, file_path, best_valid_loss)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtitletext_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# print(titletext_len.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitletext_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n6/xlg_j8tx7xzdv6qgxc7hwb680000gp/T/ipykernel_9081/4267470358.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, offsets)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0mreturned\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[0;32m--> 383\u001b[0;31m         return F.embedding_bag(input, self.weight, offsets,\n\u001b[0m\u001b[1;32m    384\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nlp-env/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding_bag\u001b[0;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m                 \u001b[0mtype_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2178\u001b[0m                 \u001b[0;34m\"if input is 2D, then offsets has to be None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m                 \u001b[0;34m\", as input is treated is a mini-batch of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: if input is 2D, then offsets has to be None, as input is treated is a mini-batch of fixed length sequences. However, found offsets of type <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "labels, text, output = train(model=model, optimizer=optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(34), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(13), tensor(13), tensor(2), tensor(1), tensor(13), tensor(13), tensor(2), tensor(1), tensor(13), tensor(1), tensor(1), tensor(1), tensor(10), tensor(2), tensor(1), tensor(1), tensor(1), tensor(10), tensor(2), tensor(1), tensor(1), tensor(1), tensor(4), tensor(2), tensor(1), tensor(1), tensor(39), tensor(3), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(13), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(38), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(25), tensor(1), tensor(23), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(36), tensor(15), tensor(1), tensor(1), tensor(1), tensor(1), tensor(9), tensor(9), tensor(4), tensor(9), tensor(4), tensor(4), tensor(1), tensor(1), tensor(4), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(23), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(11), tensor(3), tensor(1), tensor(1), tensor(1), tensor(8), tensor(3), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(8), tensor(3), tensor(1), tensor(1), tensor(1), tensor(11), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(8), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(8), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(13), tensor(2), tensor(1), tensor(1), tensor(16), tensor(1), tensor(1), tensor(1), tensor(28), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(4), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(22), tensor(4), tensor(1), tensor(22), tensor(4), tensor(33), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(1), tensor(4), tensor(1), tensor(1), tensor(17), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(13), tensor(2), tensor(1), tensor(13), tensor(13), tensor(2), tensor(1), tensor(13), tensor(2), tensor(1), tensor(1), tensor(1), tensor(39), tensor(3), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(1), tensor(16), tensor(1), tensor(1), tensor(1), tensor(33), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(4), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(16), tensor(2), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(16), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(23), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(29), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(7), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(32), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(6), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(17), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(27), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(11), tensor(3), tensor(1), tensor(1), tensor(1), tensor(8), tensor(3), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(8), tensor(3), tensor(1), tensor(1), tensor(1), tensor(14), tensor(19), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(22), tensor(4), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(12), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(16), tensor(1), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(15), tensor(1), tensor(1), tensor(1), tensor(23), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(14), tensor(19), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(11), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(1), tensor(1), tensor(1), tensor(9), tensor(9), tensor(4), tensor(9), tensor(4), tensor(4), tensor(1), tensor(1), tensor(4), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(5), tensor(1), tensor(1), tensor(3), tensor(1), tensor(1), tensor(22), tensor(4), tensor(1), tensor(27), tensor(1), tensor(1), tensor(1), tensor(3), tensor(1), tensor(2), tensor(1), tensor(1), tensor(1), tensor(29), tensor(1)]\n"
     ]
    }
   ],
   "source": [
    "print(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7588])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3169, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "668ef8e5884dc3f6c7a385d426ec114c978b2f69913d82ea0913105f6d1e06ce"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('jdi-qasp-ml': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
